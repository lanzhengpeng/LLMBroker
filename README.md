# LLMBroker

LLMBroker æ˜¯ä¸€ä¸ªç»Ÿä¸€çš„å¤§è¯­è¨€æ¨¡å‹ä»£ç†æœåŠ¡ï¼Œæä¾›ç»Ÿä¸€çš„APIæ¥å£æ¥è®¿é—®å¤šä¸ªä¸åŒçš„LLMæä¾›å•†ï¼ˆOpenAIã€Claudeã€é€šä¹‰åƒé—®ç­‰ï¼‰ã€‚

## ç‰¹æ€§

- ğŸš€ **ç»Ÿä¸€æ¥å£**: å…¼å®¹OpenAI APIæ ¼å¼ï¼Œæ”¯æŒå¤šä¸ªLLMæä¾›å•†
- ğŸ”§ **å‚æ•°æ³¨å…¥**: è‡ªåŠ¨æ³¨å…¥é»˜è®¤å‚æ•°ï¼Œæ”¯æŒå‚æ•°è¦†ç›–
- ğŸ“‹ **é…ç½®ç®¡ç†**: çµæ´»çš„YAMLé…ç½®æ–‡ä»¶ï¼Œæ”¯æŒç¯å¢ƒå˜é‡
- ğŸ›¡ï¸ **é”™è¯¯å¤„ç†**: å®Œå–„çš„é”™è¯¯å¤„ç†å’Œå“åº”æ ¼å¼åŒ–
- ğŸ“ **è¯·æ±‚æ—¥å¿—**: è¯¦ç»†çš„è¯·æ±‚æ—¥å¿—è®°å½•å’Œç›‘æ§
- ğŸ”„ **è´Ÿè½½å‡è¡¡**: æ”¯æŒå¤šæ¨¡å‹é…ç½®å’Œè½¬å‘

## æ”¯æŒçš„æ¨¡å‹æä¾›å•†

- **OpenAI**: GPT-3.5-turbo, GPT-4, GPT-4-turboç­‰
- **Anthropic**: Claude-3 ç³»åˆ—æ¨¡å‹
- **é˜¿é‡Œäº‘**: é€šä¹‰åƒé—®ç³»åˆ—æ¨¡å‹
- **æ‰©å±•æ€§**: æ˜“äºæ·»åŠ æ–°çš„æä¾›å•†æ”¯æŒ

## å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
pip install -r requirements.txt
```

### 2. é…ç½®ç¯å¢ƒå˜é‡

åˆ›å»º `.env` æ–‡ä»¶æˆ–è®¾ç½®ç¯å¢ƒå˜é‡ï¼š

```bash
# OpenAI API Key
export OPENAI_API_KEY="your-openai-api-key"

# Anthropic API Key
export ANTHROPIC_API_KEY="your-anthropic-api-key"

# é˜¿é‡Œäº‘DashScope API Key
export DASHSCOPE_API_KEY="your-dashscope-api-key"
```

### 3. ä¿®æ”¹é…ç½®æ–‡ä»¶

ç¼–è¾‘ `config.yaml` æ–‡ä»¶ï¼Œé…ç½®éœ€è¦ä½¿ç”¨çš„æ¨¡å‹ï¼š

```yaml
models:
  gpt-3.5-turbo:
    provider: "openai"
    model_name: "gpt-3.5-turbo"
    api_key: "${OPENAI_API_KEY}"
    default_params:
      temperature: 0.7
      max_tokens: 1000
```

### 4. å¯åŠ¨æœåŠ¡

```bash
# ä½¿ç”¨å¯åŠ¨è„šæœ¬
./run.sh

# æˆ–è€…ç›´æ¥è¿è¡Œ
python -m app.main

# æˆ–è€…ä½¿ç”¨uvicorn
uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
```

### 5. æµ‹è¯•API

æœåŠ¡å¯åŠ¨åï¼Œè®¿é—® `http://localhost:8000/docs` æŸ¥çœ‹APIæ–‡æ¡£ã€‚

#### èŠå¤©å®Œæˆç¤ºä¾‹

```bash
curl -X POST "http://localhost:8000/v1/chat/completions" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "gpt-3.5-turbo",
    "messages": [
      {"role": "user", "content": "Hello, how are you?"}
    ],
    "temperature": 0.7
  }'
```

#### æ–‡æœ¬å®Œæˆç¤ºä¾‹

```bash
curl -X POST "http://localhost:8000/v1/completions" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "gpt-3.5-turbo",
    "prompt": "The future of AI is",
    "max_tokens": 100
  }'
```

## APIæ¥å£

### èŠå¤©å®Œæˆ - `/v1/chat/completions`

å…¼å®¹OpenAI ChatGPT APIæ ¼å¼ï¼š

```json
{
  "model": "gpt-3.5-turbo",
  "messages": [
    {"role": "system", "content": "You are a helpful assistant."},
    {"role": "user", "content": "Hello!"}
  ],
  "temperature": 0.7,
  "max_tokens": 1000
}
```

### æ–‡æœ¬å®Œæˆ - `/v1/completions`

å…¼å®¹OpenAI Completions APIæ ¼å¼ï¼š

```json
{
  "model": "gpt-3.5-turbo",
  "prompt": "Once upon a time",
  "max_tokens": 100,
  "temperature": 0.7
}
```

### æ¨¡å‹åˆ—è¡¨ - `/models`

è·å–æ‰€æœ‰å¯ç”¨æ¨¡å‹ï¼š

```bash
curl http://localhost:8000/models
```

### å¥åº·æ£€æŸ¥ - `/health`

æœåŠ¡å¥åº·çŠ¶æ€æ£€æŸ¥ï¼š

```bash
curl http://localhost:8000/health
```

## é…ç½®è¯´æ˜

### æ¨¡å‹é…ç½®

```yaml
models:
  model-alias:  # æ¨¡å‹åˆ«åï¼Œå®¢æˆ·ç«¯ä½¿ç”¨è¿™ä¸ªåç§°
    provider: "openai"           # æä¾›å•†ï¼šopenai, claude, qwen
    model_name: "gpt-3.5-turbo"  # å®é™…æ¨¡å‹åç§°
    api_key: "${API_KEY}"        # APIå¯†é’¥ï¼ˆæ”¯æŒç¯å¢ƒå˜é‡ï¼‰
    base_url: "https://..."      # APIåŸºç¡€URL
    default_params:              # é»˜è®¤å‚æ•°
      temperature: 0.7
      max_tokens: 1000
```

### ä»£ç†é…ç½®

```yaml
proxy:
  default_model: "gpt-3.5-turbo"         # é»˜è®¤æ¨¡å‹
  enable_parameter_injection: true       # å¯ç”¨å‚æ•°æ³¨å…¥
  enable_request_logging: true          # å¯ç”¨è¯·æ±‚æ—¥å¿—
  timeout: 60                           # è¯·æ±‚è¶…æ—¶æ—¶é—´
```

## é¡¹ç›®ç»“æ„

```
LLMBroker/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py        # åŒ…åˆå§‹åŒ–
â”‚   â”œâ”€â”€ main.py            # FastAPI å…¥å£å’Œè·¯ç”±
â”‚   â”œâ”€â”€ clients.py         # å¤šæ¨¡å‹å®¢æˆ·ç«¯å°è£…
â”‚   â”œâ”€â”€ config.py          # é…ç½®åŠ è½½
â”‚   â”œâ”€â”€ proxy.py           # ä»£ç†é€»è¾‘
â”‚   â””â”€â”€ utils.py           # å·¥å…·å‡½æ•°
â”œâ”€â”€ config.yaml            # é…ç½®æ–‡ä»¶
â”œâ”€â”€ requirements.txt       # ä¾èµ–åŒ…åˆ—è¡¨
â”œâ”€â”€ README.md             # é¡¹ç›®æ–‡æ¡£
â””â”€â”€ run.sh                # å¯åŠ¨è„šæœ¬
```

## å¼€å‘æŒ‡å—

### æ·»åŠ æ–°çš„æ¨¡å‹æä¾›å•†

1. åœ¨ `clients.py` ä¸­åˆ›å»ºæ–°çš„å®¢æˆ·ç«¯ç±»ï¼Œç»§æ‰¿ `BaseModelClient`
2. å®ç° `chat_completion` å’Œ `text_completion` æ–¹æ³•
3. åœ¨ `ModelClientManager.CLIENT_CLASSES` ä¸­æ³¨å†Œæ–°å®¢æˆ·ç«¯
4. æ›´æ–°é…ç½®æ–‡ä»¶ç¤ºä¾‹

### å‚æ•°æ³¨å…¥æœºåˆ¶

ä»£ç†æœåŠ¡ä¼šè‡ªåŠ¨åˆå¹¶æ¨¡å‹çš„é»˜è®¤å‚æ•°å’Œè¯·æ±‚å‚æ•°ï¼š

1. ä»é…ç½®æ–‡ä»¶åŠ è½½æ¨¡å‹çš„é»˜è®¤å‚æ•°
2. ä»è¯·æ±‚ä¸­æå–å‚æ•°
3. åˆå¹¶å‚æ•°ï¼ˆè¯·æ±‚å‚æ•°ä¼˜å…ˆçº§æ›´é«˜ï¼‰
4. ä¼ é€’ç»™æ¨¡å‹API

### é”™è¯¯å¤„ç†

æ‰€æœ‰é”™è¯¯éƒ½ä¼šè¢«è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼ï¼š

```json
{
  "error": {
    "message": "é”™è¯¯æè¿°",
    "type": "error_type",
    "code": "ERROR_CODE"
  }
}
```

## éƒ¨ç½²æŒ‡å—

### Docker éƒ¨ç½²

```dockerfile
FROM python:3.9-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

### ç¯å¢ƒå˜é‡

ç¡®ä¿åœ¨éƒ¨ç½²ç¯å¢ƒä¸­è®¾ç½®å¿…è¦çš„APIå¯†é’¥ï¼š

```bash
OPENAI_API_KEY=your-key
ANTHROPIC_API_KEY=your-key
DASHSCOPE_API_KEY=your-key
```

## è´¡çŒ®æŒ‡å—

1. Fork é¡¹ç›®
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯ (`git checkout -b feature/AmazingFeature`)
3. æäº¤æ›´æ”¹ (`git commit -m 'Add some AmazingFeature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/AmazingFeature`)
5. æ‰“å¼€ Pull Request

## è®¸å¯è¯

MIT License

## è”ç³»æ–¹å¼

- ä½œè€…: LanZhengPeng
- é¡¹ç›®é“¾æ¥: [GitHub Repository]
