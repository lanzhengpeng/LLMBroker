# LLMBroker 配置文件

# 服务器配置
server:
  host: "0.0.0.0"
  port: 8000
  reload: true
  log_level: "info"

# 模型配置
models:
  # OpenAI GPT 模型
  gpt-3.5-turbo:
    provider: "openai"
    model_name: "gpt-3.5-turbo"
    api_key: "${OPENAI_API_KEY}"  # 环境变量
    base_url: "https://api.openai.com/v1"
    default_params:
      temperature: 0.7
      max_tokens: 1000
      top_p: 1.0
      frequency_penalty: 0.0
      presence_penalty: 0.0

  gpt-4:
    provider: "openai"
    model_name: "gpt-4"
    api_key: "${OPENAI_API_KEY}"
    base_url: "https://api.openai.com/v1"
    default_params:
      temperature: 0.7
      max_tokens: 1000
      top_p: 1.0

  gpt-4-turbo:
    provider: "openai"
    model_name: "gpt-4-turbo-preview"
    api_key: "${OPENAI_API_KEY}"
    base_url: "https://api.openai.com/v1"
    default_params:
      temperature: 0.7
      max_tokens: 2000

  # Anthropic Claude 模型
  claude-3-sonnet:
    provider: "claude"
    model_name: "claude-3-sonnet-20240229"
    api_key: "${ANTHROPIC_API_KEY}"
    base_url: "https://api.anthropic.com/v1"
    default_params:
      temperature: 0.7
      max_tokens: 1000

  claude-3-opus:
    provider: "claude"
    model_name: "claude-3-opus-20240229"
    api_key: "${ANTHROPIC_API_KEY}"
    base_url: "https://api.anthropic.com/v1"
    default_params:
      temperature: 0.7
      max_tokens: 1000

  # 阿里云通义千问模型
  qwen-turbo:
    provider: "qwen"
    model_name: "qwen-turbo"
    api_key: "${DASHSCOPE_API_KEY}"
    base_url: "https://dashscope.aliyuncs.com/api/v1"
    default_params:
      temperature: 0.7
      max_tokens: 1000

  qwen-plus:
    provider: "qwen"
    model_name: "qwen-plus"
    api_key: "${DASHSCOPE_API_KEY}"
    base_url: "https://dashscope.aliyuncs.com/api/v1"
    default_params:
      temperature: 0.7
      max_tokens: 2000

  qwen-max:
    provider: "qwen"
    model_name: "qwen-max"
    api_key: "${DASHSCOPE_API_KEY}"
    base_url: "https://dashscope.aliyuncs.com/api/v1"
    default_params:
      temperature: 0.7
      max_tokens: 2000

# 代理配置
proxy:
  # 默认模型（当请求中没有指定模型时使用）
  default_model: "gpt-3.5-turbo"
  
  # 是否启用参数注入（将默认参数与请求参数合并）
  enable_parameter_injection: true
  
  # 是否启用请求日志记录
  enable_request_logging: true
  
  # 请求超时时间（秒）
  timeout: 60
  
  # 是否启用响应缓存
  enable_response_cache: false
  
  # 缓存过期时间（秒）
  cache_ttl: 300

# 日志配置
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: "logs/llmbroker.log"

# 安全配置
security:
  # 允许的来源（CORS）
  allowed_origins:
    - "*"
  
  # 是否启用API密钥验证
  enable_api_key_auth: false
  
  # API密钥列表（如果启用验证）
  api_keys: []

# 监控配置
monitoring:
  # 是否启用指标收集
  enable_metrics: true
  
  # 指标导出端口
  metrics_port: 9090
  
  # 健康检查间隔（秒）
  health_check_interval: 30
